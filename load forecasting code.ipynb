{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yk_SUYNVVJLv"
   },
   "outputs": [],
   "source": [
    "## Keras implementation of day-ahead prediction of the ISO-NE hourly demand data.\n",
    " \n",
    "# -----------------------------------------------------------------------------\n",
    "# load original data file\n",
    "# modification of the data loading procedure is needed if you have your own dataset\n",
    " \n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53014,
     "status": "ok",
     "timestamp": 1593462163924,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "GXDMCHF4kMkL",
    "outputId": "0671870a-171f-4482-b0c3-710fd5011187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0AFG2W3VJL4"
   },
   "outputs": [],
   "source": [
    "parse_dates = ['date'] \n",
    "df = pd.read_csv('/content/drive/My Drive/exploproject/load-forecasting-resnet-master/ISO-NE/selected_data_ISONE.csv', parse_dates=parse_dates, index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1960,
     "status": "ok",
     "timestamp": 1593464571803,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "vIvZz0ECVJMI",
    "outputId": "bc562588-3e74-4ada-d98e-468192ce9a46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>demand</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-03-01</th>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12863.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-01</th>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12389.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-01</th>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12155.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-01</th>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>12072.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-01</th>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12160.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>16955.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>16243.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>15525.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>14759.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>14071.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103776 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            year  month  day  weekday  hour   demand  temperature\n",
       "date                                                             \n",
       "2003-03-01  2003      3    1        7     1  12863.0           23\n",
       "2003-03-01  2003      3    1        7     2  12389.0           22\n",
       "2003-03-01  2003      3    1        7     3  12155.0           21\n",
       "2003-03-01  2003      3    1        7     4  12072.0           21\n",
       "2003-03-01  2003      3    1        7     5  12160.0           22\n",
       "...          ...    ...  ...      ...   ...      ...          ...\n",
       "2014-12-31  2014     12   31        4    20  16955.0           22\n",
       "2014-12-31  2014     12   31        4    21  16243.0           21\n",
       "2014-12-31  2014     12   31        4    22  15525.0           21\n",
       "2014-12-31  2014     12   31        4    23  14759.0           18\n",
       "2014-12-31  2014     12   31        4    24  14071.0           19\n",
       "\n",
       "[103776 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aeEFIfjyfDRk"
   },
   "outputs": [],
   "source": [
    "# 1. get the maximum and minimum demands in 0-24 clock intervals\n",
    "# 2. get the daily demand and temperature values\n",
    "#D_max_daily = df.groupby('date').demand.max().get_values()\n",
    "d = df.groupby('date')['demand'].apply(list)\n",
    "\n",
    "D_max_daily = []\n",
    "for i in range(len(d)):\n",
    "  for j in range(len(d[i])):\n",
    "    D_max_daily.append(np.max(d[i]))\n",
    "\n",
    "#D_min_daily = df.groupby('date').demand.min().get_values()\n",
    "D_min_daily = []\n",
    "for i in range(len(d)):\n",
    "  for j in range(len(d[i])):\n",
    "    D_min_daily.append(min(d[i]))\n",
    "\n",
    "\n",
    "#D = df.demand.get_values()\n",
    "D = df[\"demand\"].tolist()\n",
    "#T = df.temperature.get_values()\n",
    "T = df[\"temperature\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1KwMrYWVJMi"
   },
   "outputs": [],
   "source": [
    "# 1. get the maximum and minimum demands in 0-24 clock intervals\n",
    "# 2. get the daily demand and temperature values\n",
    "#D_max_daily = df.groupby('date').demand.max().get_values()\n",
    "#D_min_daily = df.groupby('date').demand.min().get_values()\n",
    "#D = df.demand.get_values()\n",
    "#T = df.temperature.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UCFJkYcVJMx"
   },
   "outputs": [],
   "source": [
    "# duplicate max and min daily demand values for 24 hours in a day\n",
    "D_max = np.zeros(len(D))\n",
    "D_min = np.zeros(len(D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7xOz854VJM3"
   },
   "outputs": [],
   "source": [
    "for i in range(len(D)):\n",
    "    n_day = int(i/24)\n",
    "    D_max[i] = D_max_daily[n_day]\n",
    "    D_min[i] = D_min_daily[n_day]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-1--c84VJM9"
   },
   "outputs": [],
   "source": [
    "D = np.array(D)\n",
    "T = np.array(T)\n",
    "# normalization based on peak values\n",
    "D_max = D_max / 24000.\n",
    "D_min = D_min / 24000.\n",
    "D = D / 24000.\n",
    "T = T / 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkwmtbdmVJND"
   },
   "outputs": [],
   "source": [
    "# add weekday info to the dataset\n",
    "# the initial value for iter_weekday corresponds to the first day of the dataset\n",
    "iter_weekday = 6\n",
    "weekday = np.zeros((24*4324,))\n",
    "for i in range(4324):\n",
    "    mod = np.mod(iter_weekday, 7)\n",
    "    for j in range(24):\n",
    "        if (mod == 6) or (mod == 0):\n",
    "            weekday[i*24 + j] = 0\n",
    "        else:\n",
    "            weekday[i*24 + j] = 1\n",
    "    iter_weekday += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cZM1phsVJNH"
   },
   "outputs": [],
   "source": [
    "# add season and festival info to the dataset\n",
    "import datetime\n",
    "iter_date = datetime.date(2003, 3, 1)\n",
    "season = np.zeros((24*4324,))\n",
    "festival = np.zeros((24*4324,))\n",
    "for i in range(4324):\n",
    "    month = iter_date.month\n",
    "    day = iter_date.day\n",
    "    for j in range(24):\n",
    "        if (month==4) | (month==5) | ((month==3) and (day>7)) | ((month==6) and (day<8)):\n",
    "            season[i*24 + j] = 0\n",
    "        elif (month==7) | (month==8) | ((month==6) and (day>7)) | ((month==9) and (day<8)):\n",
    "            season[i*24 + j] = 1\n",
    "        elif (month==10) | (month==11) | ((month==9) and (day>7)) | ((month==12) and (day<8)):\n",
    "            season[i*24 + j] = 2\n",
    "        elif (month==1) | (month==2) | ((month==12) and (day>7)) | ((month==3) and (day<8)):\n",
    "            season[i*24 + j] = 3\n",
    "\n",
    "        if (month == 7) and (day == 4):\n",
    "            festival[i*24 + j] = 1\n",
    "        if (month == 11) and (iter_date.weekday() == 4) and (day + 7 > 30):\n",
    "            festival[i*24 + j] = 1\n",
    "        if (month == 12) and (day == 25):\n",
    "            festival[i*24 + j] = 1\n",
    "    iter_date = iter_date + datetime.timedelta(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjWoJ47KVJNL"
   },
   "outputs": [],
   "source": [
    "def data_split(D, T, D_max, D_min, season, weekday, festival, num_train_days, validation_split = 0.1):\n",
    "    '''\n",
    "    prepare the dataset used for training and testing of the model.\n",
    "    '''\n",
    "    x_1 = []\n",
    "    x_21_D = []\n",
    "    x_21_T = []\n",
    "    x_22_D = []\n",
    "    x_22_T = []\n",
    "    x_23_D = []\n",
    "    x_23_T = []\n",
    "    x_3 = []\n",
    "    x_4 = []\n",
    "    x_5 = []\n",
    "    x_season = []\n",
    "    x_weekday = []\n",
    "    x_festival = []\n",
    "    y = []\n",
    "    \n",
    "    len_dataset = D.shape[0]\n",
    "    num_sample = len_dataset-2016\n",
    "    # 2016 hours (28*3 days) is needed so that we can formulate the first datapoint\n",
    "    for i in range(2016,len_dataset):   \n",
    "        # the demand values of the most recent 24 hours\n",
    "        x_1.append(D[i-24:i])\n",
    "        \n",
    "        # multiple demand values every 24 hours within a week\n",
    "        index_x_21 = [i-24, i-48, i-72, i-96, i-120, i-144, i-168]\n",
    "        x_21_D.append(D[index_x_21])\n",
    "        x_21_T.append(T[index_x_21])\n",
    "        \n",
    "        # multiple demand values every week within two months\n",
    "        index_x_22 = [i-168, i-336, i-504, i-672, i-840, i-1008, i-1176, i-1344]\n",
    "        x_22_D.append(D[index_x_22])\n",
    "        x_22_T.append(T[index_x_22])\n",
    "        \n",
    "        # multiple demand values every month within several months\n",
    "        index_x_23 = [i-672, i-1344, i-2016]\n",
    "        x_23_D.append(D[index_x_23])\n",
    "        x_23_T.append(T[index_x_23])\n",
    "        \n",
    "        x_3.append(T[i])\n",
    "        x_4.append(D_max[i])\n",
    "        x_5.append(D_min[i])\n",
    "        \n",
    "        y.append(D[i])\n",
    "        \n",
    "        # get one-hot representations of the additional information\n",
    "        season_onehot = np.zeros(4)\n",
    "        season_onehot[int(season[i])] = 1 \n",
    "        x_season.append(season_onehot)\n",
    "\n",
    "        weekday_onehot = np.zeros(2)\n",
    "        weekday_onehot[int(weekday[i])] = 1 \n",
    "        x_weekday.append(weekday_onehot)\n",
    "\n",
    "        festival_onehot = np.zeros(2)\n",
    "        festival_onehot[int(festival[i])] = 1 \n",
    "        x_festival.append(festival_onehot)\n",
    "        \n",
    "    X_1 = np.array(x_1)\n",
    "    X_21_D = np.array(x_21_D)\n",
    "    X_21_T = np.array(x_21_T)\n",
    "    X_22_D = np.array(x_22_D)\n",
    "    X_22_T = np.array(x_22_T)\n",
    "    X_23_D = np.array(x_23_D)\n",
    "    X_23_T = np.array(x_23_T)\n",
    "    X_3 = np.array(x_3)\n",
    "    X_4 = np.array(x_4)\n",
    "    X_5 = np.array(x_5)\n",
    "    X_season = np.array(x_season)\n",
    "    X_weekday = np.array(x_weekday)\n",
    "    X_festival = np.array(x_festival)\n",
    "    Y_1 = np.array(y)\n",
    "    \n",
    "    num_train = num_train_days * 24\n",
    "    num_val = int(num_train * validation_split)\n",
    "    \n",
    "    X_train = []\n",
    "    X_val = []\n",
    "    X_test = []\n",
    "    Y_train = []\n",
    "    Y_val = []\n",
    "    Y_test = []\n",
    "    \n",
    "    # we prepare 24 sets of data for the 24 sub-networks, each sub-network is aimed at forecasting the load of one hour of the next day\n",
    "    for i in range(24):\n",
    "        #               0                          1                         2                         3                         4                         5                         6                         7                    8                    9                    10                          11                           12                                              \n",
    "        X_train.append([X_1[i:num_train:24,:24-i], X_21_D[i:num_train:24,:], X_21_T[i:num_train:24,:], X_22_D[i:num_train:24,:], X_22_T[i:num_train:24,:], X_23_D[i:num_train:24,:], X_23_T[i:num_train:24,:], X_3[i:num_train:24], X_4[i:num_train:24], X_5[i:num_train:24], X_season[i:num_train:24,:], X_weekday[i:num_train:24,:], X_festival[i:num_train:24,:]])\n",
    "        X_val.append([X_1[num_train-num_val+i:num_train:24,:24-i], X_21_D[num_train-num_val+i:num_train:24,:], X_21_T[num_train-num_val+i:num_train:24,:], X_22_D[num_train-num_val+i:num_train:24,:], X_22_T[num_train-num_val+i:num_train:24,:], X_23_D[num_train-num_val+i:num_train:24,:], X_23_T[num_train-num_val+i:num_train:24,:], X_3[num_train-num_val+i:num_train:24], X_4[num_train-num_val+i:num_train:24], X_5[num_train-num_val+i:num_train:24], X_season[num_train-num_val+i:num_train:24,:], X_weekday[num_train-num_val+i:num_train:24,:], X_festival[num_train-num_val+i:num_train:24,:]])\n",
    "        X_test.append([X_1[num_train+i:num_sample:24,:24-i], X_21_D[num_train+i:num_sample:24,:], X_21_T[num_train+i:num_sample:24,:], X_22_D[num_train+i:num_sample:24,:], X_22_T[num_train+i:num_sample:24,:], X_23_D[num_train+i:num_sample:24,:], X_23_T[num_train+i:num_sample:24,:], X_3[num_train+i:num_sample:24], X_4[num_train+i:num_sample:24], X_5[num_train+i:num_sample:24], X_season[num_train+i:num_sample:24,:], X_weekday[num_train+i:num_sample:24,:], X_festival[num_train+i:num_sample:24,:]])\n",
    "        Y_train.append(Y_1[i:num_train:24])\n",
    "        Y_val.append(Y_1[num_train-num_val+i:num_train:24])\n",
    "        Y_test.append(Y_1[num_train+i:num_sample:24])\n",
    "\n",
    "    return (X_train, X_val, X_test, Y_train, Y_val, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rr0ZHMDGVJNV"
   },
   "outputs": [],
   "source": [
    "# num_pre_days: the number of days we need before we can get the first sample, in this case: 3*28 days \n",
    "num_pre_days = 84\n",
    "num_days = 1401\n",
    "num_test_days = 365\n",
    "num_train_days = 952\n",
    "num_data_points = num_days * 24\n",
    "num_days_start = num_days - num_pre_days - num_test_days - num_train_days\n",
    "start_data_point = num_days_start * 24\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test = data_split(D[start_data_point: start_data_point + num_data_points], T[start_data_point: start_data_point + num_data_points], D_max[start_data_point: start_data_point + num_data_points], D_min[start_data_point: start_data_point + num_data_points], season[start_data_point: start_data_point + num_data_points], weekday[start_data_point: start_data_point + num_data_points], festival[start_data_point: start_data_point + num_data_points], num_train_days, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23312,
     "status": "ok",
     "timestamp": 1593464593367,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "XisMf97jVJNc",
    "outputId": "888cd90a-6ce0-49e9-89c1-1859b73838f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## ----------------------------------------------------------------------------\n",
    "# define the model\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, concatenate, Activation, add, BatchNormalization\n",
    "from keras.layers.merge import multiply, maximum, dot, average\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_absolute_percentage_error, hinge\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.callbacks import EarlyStopping \n",
    "from keras.optimizers import SGD, adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nvGRAHJEVJNl"
   },
   "outputs": [],
   "source": [
    "def get_input(hour):\n",
    "    input_Dd = Input(shape=(7,), name='input'+str(hour)+'_Dd')\n",
    "    input_Dw = Input(shape=(8,), name='input'+str(hour)+'_Dw')\n",
    "    input_Dm = Input(shape=(3,), name='input'+str(hour)+'_Dm')\n",
    "    input_Dr = Input(shape=(24-hour+1,), name='input'+str(hour)+'_Dr')\n",
    "    \n",
    "    input_Td = Input(shape=(7,), name='input'+str(hour)+'_Td')\n",
    "    input_Tw = Input(shape=(8,), name='input'+str(hour)+'_Tw')\n",
    "    input_Tm = Input(shape=(3,), name='input'+str(hour)+'_Tm')\n",
    "    \n",
    "    input_T = Input(shape=(1,))\n",
    "    \n",
    "    return (input_Dd, input_Dw, input_Dm, input_Dr, input_Td, input_Tw, input_Tm, input_T)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxoAHaHLVJNv"
   },
   "outputs": [],
   "source": [
    "input1_Dd, input1_Dw, input1_Dm, input1_Dr, input1_Td, input1_Tw, input1_Tm, input1_T = get_input(1)\n",
    "input2_Dd, input2_Dw, input2_Dm, input2_Dr, input2_Td, input2_Tw, input2_Tm, input2_T = get_input(2)\n",
    "input3_Dd, input3_Dw, input3_Dm, input3_Dr, input3_Td, input3_Tw, input3_Tm, input3_T = get_input(3)\n",
    "input4_Dd, input4_Dw, input4_Dm, input4_Dr, input4_Td, input4_Tw, input4_Tm, input4_T = get_input(4)\n",
    "input5_Dd, input5_Dw, input5_Dm, input5_Dr, input5_Td, input5_Tw, input5_Tm, input5_T = get_input(5)\n",
    "input6_Dd, input6_Dw, input6_Dm, input6_Dr, input6_Td, input6_Tw, input6_Tm, input6_T = get_input(6)\n",
    "input7_Dd, input7_Dw, input7_Dm, input7_Dr, input7_Td, input7_Tw, input7_Tm, input7_T = get_input(7)\n",
    "input8_Dd, input8_Dw, input8_Dm, input8_Dr, input8_Td, input8_Tw, input8_Tm, input8_T = get_input(8)\n",
    "input9_Dd, input9_Dw, input9_Dm, input9_Dr, input9_Td, input9_Tw, input9_Tm, input9_T = get_input(9)\n",
    "input10_Dd, input10_Dw, input10_Dm, input10_Dr, input10_Td, input10_Tw, input10_Tm, input10_T = get_input(10)\n",
    "input11_Dd, input11_Dw, input11_Dm, input11_Dr, input11_Td, input11_Tw, input11_Tm, input11_T = get_input(11)\n",
    "input12_Dd, input12_Dw, input12_Dm, input12_Dr, input12_Td, input12_Tw, input12_Tm, input12_T = get_input(12)\n",
    "input13_Dd, input13_Dw, input13_Dm, input13_Dr, input13_Td, input13_Tw, input13_Tm, input13_T = get_input(13)\n",
    "input14_Dd, input14_Dw, input14_Dm, input14_Dr, input14_Td, input14_Tw, input14_Tm, input14_T = get_input(14)\n",
    "input15_Dd, input15_Dw, input15_Dm, input15_Dr, input15_Td, input15_Tw, input15_Tm, input15_T = get_input(15)\n",
    "input16_Dd, input16_Dw, input16_Dm, input16_Dr, input16_Td, input16_Tw, input16_Tm, input16_T = get_input(16)\n",
    "input17_Dd, input17_Dw, input17_Dm, input17_Dr, input17_Td, input17_Tw, input17_Tm, input17_T = get_input(17)\n",
    "input18_Dd, input18_Dw, input18_Dm, input18_Dr, input18_Td, input18_Tw, input18_Tm, input18_T = get_input(18)\n",
    "input19_Dd, input19_Dw, input19_Dm, input19_Dr, input19_Td, input19_Tw, input19_Tm, input19_T = get_input(19)\n",
    "input20_Dd, input20_Dw, input20_Dm, input20_Dr, input20_Td, input20_Tw, input20_Tm, input20_T = get_input(20)\n",
    "input21_Dd, input21_Dw, input21_Dm, input21_Dr, input21_Td, input21_Tw, input21_Tm, input21_T = get_input(21)\n",
    "input22_Dd, input22_Dw, input22_Dm, input22_Dr, input22_Td, input22_Tw, input22_Tm, input22_T = get_input(22)\n",
    "input23_Dd, input23_Dw, input23_Dm, input23_Dr, input23_Td, input23_Tw, input23_Tm, input23_T = get_input(23)\n",
    "input24_Dd, input24_Dw, input24_Dm, input24_Dr, input24_Td, input24_Tw, input24_Tm, input24_T = get_input(24)\n",
    "\n",
    "input_D_max = Input(shape=(1,), name='input_D_max')\n",
    "input_D_min = Input(shape=(1,), name='input_D_min')\n",
    "input_season = Input(shape=(4,), name='input_season')\n",
    "input_weekday = Input(shape=(2,), name='input_weekday')\n",
    "input_festival = Input(shape=(2,), name='input_festival')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t0QT97dMVJN4"
   },
   "outputs": [],
   "source": [
    "def get_basic_structure(hour, input_Dd, input_Dw, input_Dm, input_Dr, input_Td, input_Tw, input_Tm, input_T, output_pre=[]):\n",
    "    '''\n",
    "    get the module with the basic structure.\n",
    "    output_pre is used to replace the recent 24-hour inputs with the outputs of basic-structure modules of previous hours.\n",
    "    '''\n",
    "    num_dense = 10\n",
    "    \n",
    "    dense_Dd = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(input_Dd)\n",
    "    dense_Dw = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(input_Dw)\n",
    "    dense_Dm = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(input_Dm)\n",
    "    dense_Td = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(input_Td)\n",
    "    dense_Tw = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(input_Tw)\n",
    "    dense_Tm = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(input_Tm)\n",
    "    \n",
    "    concat_d = concatenate([dense_Dd, dense_Td])\n",
    "    dense_d = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(concat_d)\n",
    "    \n",
    "    concat_w = concatenate([dense_Dw, dense_Tw])\n",
    "    dense_w = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(concat_w)\n",
    "    \n",
    "    concat_m = concatenate([dense_Dm, dense_Tm])\n",
    "    dense_m = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(concat_m)\n",
    "    \n",
    "    concat_date_info = concatenate([input_season, input_weekday])\n",
    "    dense_concat_date_info_1 = Dense(5, activation='selu', kernel_initializer='lecun_normal')(concat_date_info)\n",
    "    dense_concat_date_info_2 = Dense(5, activation='selu', kernel_initializer='lecun_normal')(concat_date_info)\n",
    "    \n",
    "    concat_FC2 = concatenate([dense_d, dense_w, dense_m, dense_concat_date_info_1, input_festival])\n",
    "    dense_FC2 = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(concat_FC2)\n",
    "    \n",
    "    if output_pre == []:\n",
    "        dense_Dr = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(input_Dr)\n",
    "    else:\n",
    "        concat_Dr = concatenate([input_Dr] + output_pre)\n",
    "        dense_Dr = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(concat_Dr)\n",
    "    dense_FC1 = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(concatenate([dense_Dr, dense_concat_date_info_2]))\n",
    "        \n",
    "    concat = concatenate([dense_FC2, dense_FC1, input_T])\n",
    "    dense_pre_output = Dense(num_dense, activation='selu', kernel_initializer='lecun_normal')(concat)\n",
    "    \n",
    "    output = Dense(1, activation='linear', name='output'+str(hour), kernel_initializer='lecun_normal')(dense_pre_output)\n",
    "    \n",
    "    output_pre_new = output_pre + [output]\n",
    "    return (output, output_pre_new)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HV47staqVJOE"
   },
   "outputs": [],
   "source": [
    "output1, output_pre1 = get_basic_structure(1, input1_Dd, input1_Dw, input1_Dm, input1_Dr, input1_Td, input1_Tw, input1_Tm, input1_T)\n",
    "output2, output_pre2 = get_basic_structure(2, input2_Dd, input2_Dw, input2_Dm, input2_Dr, input2_Td, input2_Tw, input2_Tm, input2_T, output_pre1)\n",
    "output3, output_pre3 = get_basic_structure(3, input3_Dd, input3_Dw, input3_Dm, input3_Dr, input3_Td, input3_Tw, input3_Tm, input3_T, output_pre2)\n",
    "output4, output_pre4 = get_basic_structure(4, input4_Dd, input4_Dw, input4_Dm, input4_Dr, input4_Td, input4_Tw, input4_Tm, input4_T, output_pre3)\n",
    "output5, output_pre5 = get_basic_structure(5, input5_Dd, input5_Dw, input5_Dm, input5_Dr, input5_Td, input5_Tw, input5_Tm, input5_T, output_pre4)\n",
    "output6, output_pre6 = get_basic_structure(6, input6_Dd, input6_Dw, input6_Dm, input6_Dr, input6_Td, input6_Tw, input6_Tm, input6_T, output_pre5)\n",
    "output7, output_pre7 = get_basic_structure(7, input7_Dd, input7_Dw, input7_Dm, input7_Dr, input7_Td, input7_Tw, input7_Tm, input7_T, output_pre6)\n",
    "output8, output_pre8 = get_basic_structure(8, input8_Dd, input8_Dw, input8_Dm, input8_Dr, input8_Td, input8_Tw, input8_Tm, input8_T, output_pre7)\n",
    "output9, output_pre9 = get_basic_structure(9, input9_Dd, input9_Dw, input9_Dm, input9_Dr, input9_Td, input9_Tw, input9_Tm, input9_T, output_pre8)\n",
    "output10, output_pre10 = get_basic_structure(10, input10_Dd, input10_Dw, input10_Dm, input10_Dr, input10_Td, input10_Tw, input10_Tm, input10_T, output_pre9)\n",
    "output11, output_pre11 = get_basic_structure(11, input11_Dd, input11_Dw, input11_Dm, input11_Dr, input11_Td, input11_Tw, input11_Tm, input11_T, output_pre10)\n",
    "output12, output_pre12 = get_basic_structure(12, input12_Dd, input12_Dw, input12_Dm, input12_Dr, input12_Td, input12_Tw, input12_Tm, input12_T, output_pre11)\n",
    "output13, output_pre13 = get_basic_structure(13, input13_Dd, input13_Dw, input13_Dm, input13_Dr, input13_Td, input13_Tw, input13_Tm, input13_T, output_pre12)\n",
    "output14, output_pre14 = get_basic_structure(14, input14_Dd, input14_Dw, input14_Dm, input14_Dr, input14_Td, input14_Tw, input14_Tm, input14_T, output_pre13)\n",
    "output15, output_pre15 = get_basic_structure(15, input15_Dd, input15_Dw, input15_Dm, input15_Dr, input15_Td, input15_Tw, input15_Tm, input15_T, output_pre14)\n",
    "output16, output_pre16 = get_basic_structure(16, input16_Dd, input16_Dw, input16_Dm, input16_Dr, input16_Td, input16_Tw, input16_Tm, input16_T, output_pre15)\n",
    "output17, output_pre17 = get_basic_structure(17, input17_Dd, input17_Dw, input17_Dm, input17_Dr, input17_Td, input17_Tw, input17_Tm, input17_T, output_pre16)\n",
    "output18, output_pre18 = get_basic_structure(18, input18_Dd, input18_Dw, input18_Dm, input18_Dr, input18_Td, input18_Tw, input18_Tm, input18_T, output_pre17)\n",
    "output19, output_pre19 = get_basic_structure(19, input19_Dd, input19_Dw, input19_Dm, input19_Dr, input19_Td, input19_Tw, input19_Tm, input19_T, output_pre18)\n",
    "output20, output_pre20 = get_basic_structure(20, input20_Dd, input20_Dw, input20_Dm, input20_Dr, input20_Td, input20_Tw, input20_Tm, input20_T, output_pre19)\n",
    "output21, output_pre21 = get_basic_structure(21, input21_Dd, input21_Dw, input21_Dm, input21_Dr, input21_Td, input21_Tw, input21_Tm, input21_T, output_pre20)\n",
    "output22, output_pre22 = get_basic_structure(22, input22_Dd, input22_Dw, input22_Dm, input22_Dr, input22_Td, input22_Tw, input22_Tm, input22_T, output_pre21)\n",
    "output23, output_pre23 = get_basic_structure(23, input23_Dd, input23_Dw, input23_Dm, input23_Dr, input23_Td, input23_Tw, input23_Tm, input23_T, output_pre22)\n",
    "output24, output_pre24 = get_basic_structure(24, input24_Dd, input24_Dw, input24_Dm, input24_Dr, input24_Td, input24_Tw, input24_Tm, input24_T, output_pre23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0fYnSdyVJOL"
   },
   "outputs": [],
   "source": [
    "def get_res_layer(output, last=False):\n",
    "    '''\n",
    "    obtain one basic layer in the deep residual network\n",
    "    '''\n",
    "    dense_res11 = Dense(20, activation='selu', kernel_initializer='lecun_normal')(output)\n",
    "    dense_res12 = Dense(24, activation='linear', kernel_initializer='lecun_normal')(dense_res11)\n",
    "    \n",
    "    dense_res21 = Dense(20, activation='selu', kernel_initializer='lecun_normal')(output)\n",
    "    dense_res22 = Dense(24, activation='linear', kernel_initializer='lecun_normal')(dense_res21)\n",
    "\n",
    "    dense_res31 = Dense(20, activation='selu', kernel_initializer='lecun_normal')(output)\n",
    "    dense_res32 = Dense(24, activation='linear', kernel_initializer='lecun_normal')(dense_res31)\n",
    "\n",
    "    dense_res41 = Dense(20, activation='selu', kernel_initializer='lecun_normal')(output)\n",
    "    dense_res42 = Dense(24, activation='linear', kernel_initializer='lecun_normal')(dense_res41)\n",
    "    \n",
    "    dense_add = add([dense_res12, dense_res22, dense_res32, dense_res42])\n",
    "    \n",
    "    if last:\n",
    "        output_new = add([dense_add, output], name='output')\n",
    "    else:\n",
    "        output_new = add([dense_add, output])\n",
    "    return output_new\n",
    "\n",
    "output_pre = concatenate(output_pre24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8lvAWsbVJOQ"
   },
   "outputs": [],
   "source": [
    "def resnetplus_layer(input_1, input_2, output_list):\n",
    "    '''\n",
    "    obtain one layer in ResNetPlus.\n",
    "    '''\n",
    "    output_res = get_res_layer(input_1)\n",
    "    output_res_ = get_res_layer(input_2)\n",
    "    output_res_ave_mid = average([output_res, output_res_])\n",
    "    output_list.append(output_res_ave_mid)\n",
    "    output_res_ave = average(output_list)\n",
    "    return output_res_ave, output_list\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0A_txaAQVJOU"
   },
   "outputs": [],
   "source": [
    "input_1 = output_pre\n",
    "input_2 = output_pre\n",
    "output_list = [output_pre]\n",
    "\n",
    "num_resnetplus_layer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMIAOaLDVJOY"
   },
   "outputs": [],
   "source": [
    "for i in range(num_resnetplus_layer):\n",
    "    output_res_ave, output_list = resnetplus_layer(input_1, input_2, output_list)\n",
    "    input_1 = output_res_ave\n",
    "    if i == 0:\n",
    "        input_2 = output_res_ave\n",
    "\n",
    "output = output_res_ave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGEM9Pt-VJOb"
   },
   "outputs": [],
   "source": [
    "def penalized_loss(y_true, y_pred):\n",
    "    '''\n",
    "    the loss that penalizes the model when the forcast demand is output of the boundaries for the day's actual demand.\n",
    "    '''\n",
    "    beta = 0.5\n",
    "    loss1 = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    loss2 = K.mean(K.maximum(K.max(y_pred, axis=1) - input_D_max, 0.), axis=-1)\n",
    "    loss3 = K.mean(K.maximum(input_D_min - K.min(y_pred, axis=1), 0.), axis=-1)\n",
    "    return loss1 + beta * (loss2 + loss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtTzea9mVJOg"
   },
   "outputs": [],
   "source": [
    "def get_XY(X, Y):\n",
    "    X_new = []\n",
    "    Y_new = []\n",
    "    for i in range(24):\n",
    "        X_new.append(X[i][1])\n",
    "        X_new.append(X[i][3])\n",
    "        X_new.append(X[i][5])\n",
    "        X_new.append(X[i][0])\n",
    "        X_new.append(X[i][2])\n",
    "        X_new.append(X[i][4])\n",
    "        X_new.append(X[i][6])\n",
    "        X_new.append(X[i][7]) # temperature\n",
    "        Y_new.append(Y[i])\n",
    "    X_new = X_new + [X[0][8], X[0][9], X[0][10], X[0][11], X[0][12]]\n",
    "    Y_new = [np.squeeze(np.array(Y_new)).transpose()] # the aggregate output of 24 single outputs\n",
    "    return (X_new, Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SR1omyxlVJOq"
   },
   "outputs": [],
   "source": [
    "\n",
    "## ----------------------------------------------------------------------------\n",
    "# compile and train the model\n",
    "\n",
    "X_train_fit, Y_train_fit = get_XY(X_train, Y_train)\n",
    "X_val, Y_val = get_XY(X_val, Y_val)\n",
    "X_test_pred, Y_test_pred = get_XY(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VGjfibfdVJOw"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Model(inputs=[input1_Dd, input1_Dw, input1_Dm, input1_Dr, input1_Td, input1_Tw, input1_Tm, input1_T,\\\n",
    "                      input2_Dd, input2_Dw, input2_Dm, input2_Dr, input2_Td, input2_Tw, input2_Tm, input2_T,\\\n",
    "                      input3_Dd, input3_Dw, input3_Dm, input3_Dr, input3_Td, input3_Tw, input3_Tm, input3_T,\\\n",
    "                      input4_Dd, input4_Dw, input4_Dm, input4_Dr, input4_Td, input4_Tw, input4_Tm, input4_T,\\\n",
    "                      input5_Dd, input5_Dw, input5_Dm, input5_Dr, input5_Td, input5_Tw, input5_Tm, input5_T,\\\n",
    "                      input6_Dd, input6_Dw, input6_Dm, input6_Dr, input6_Td, input6_Tw, input6_Tm, input6_T,\\\n",
    "                      input7_Dd, input7_Dw, input7_Dm, input7_Dr, input7_Td, input7_Tw, input7_Tm, input7_T,\\\n",
    "                      input8_Dd, input8_Dw, input8_Dm, input8_Dr, input8_Td, input8_Tw, input8_Tm, input8_T,\\\n",
    "                      input9_Dd, input9_Dw, input9_Dm, input9_Dr, input9_Td, input9_Tw, input9_Tm, input9_T,\\\n",
    "                      input10_Dd, input10_Dw, input10_Dm, input10_Dr, input10_Td, input10_Tw, input10_Tm, input10_T,\\\n",
    "                      input11_Dd, input11_Dw, input11_Dm, input11_Dr, input11_Td, input11_Tw, input11_Tm, input11_T,\\\n",
    "                      input12_Dd, input12_Dw, input12_Dm, input12_Dr, input12_Td, input12_Tw, input12_Tm, input12_T,\\\n",
    "                      input13_Dd, input13_Dw, input13_Dm, input13_Dr, input13_Td, input13_Tw, input13_Tm, input13_T,\\\n",
    "                      input14_Dd, input14_Dw, input14_Dm, input14_Dr, input14_Td, input14_Tw, input14_Tm, input14_T,\\\n",
    "                      input15_Dd, input15_Dw, input15_Dm, input15_Dr, input15_Td, input15_Tw, input15_Tm, input15_T,\\\n",
    "                      input16_Dd, input16_Dw, input16_Dm, input16_Dr, input16_Td, input16_Tw, input16_Tm, input16_T,\\\n",
    "                      input17_Dd, input17_Dw, input17_Dm, input17_Dr, input17_Td, input17_Tw, input17_Tm, input17_T,\\\n",
    "                      input18_Dd, input18_Dw, input18_Dm, input18_Dr, input18_Td, input18_Tw, input18_Tm, input18_T,\\\n",
    "                      input19_Dd, input19_Dw, input19_Dm, input19_Dr, input19_Td, input19_Tw, input19_Tm, input19_T,\\\n",
    "                      input20_Dd, input20_Dw, input20_Dm, input20_Dr, input20_Td, input20_Tw, input20_Tm, input20_T,\\\n",
    "                      input21_Dd, input21_Dw, input21_Dm, input21_Dr, input21_Td, input21_Tw, input21_Tm, input21_T,\\\n",
    "                      input22_Dd, input22_Dw, input22_Dm, input22_Dr, input22_Td, input22_Tw, input22_Tm, input22_T,\\\n",
    "                      input23_Dd, input23_Dw, input23_Dm, input23_Dr, input23_Td, input23_Tw, input23_Tm, input23_T,\\\n",
    "                      input24_Dd, input24_Dw, input24_Dm, input24_Dr, input24_Td, input24_Tw, input24_Tm, input24_T,\\\n",
    "                      input_D_max, input_D_min, input_season, input_weekday, input_festival], \\\n",
    "                      outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuNg0vDvVJO-"
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.compile(optimizer='adam', loss=penalized_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKf0fMaEVJPO"
   },
   "outputs": [],
   "source": [
    "def shuffle_weights(model, weights=None):\n",
    "    \"\"\"Randomly permute the weights in `model`, or the given `weights`.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = model.get_weights()\n",
    "    weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "    model.set_weights(weights)\n",
    "\n",
    "NUM_REPEAT = 5\n",
    "NUM_SNAPSHOTS = 3\n",
    "NUM_TEST_DAYS = 365\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2294618,
     "status": "ok",
     "timestamp": 1593466864919,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "XC0GyEZjVJPW",
    "outputId": "2de7fcab-2d73-41fb-b230-6aea5118cbf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "952/952 [==============================] - 88s 93ms/step - loss: 43.1898\n",
      "Epoch 2/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 12.3353\n",
      "Epoch 3/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 8.1879\n",
      "Epoch 4/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 6.6725\n",
      "Epoch 5/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.7187\n",
      "Epoch 6/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.6907\n",
      "Epoch 7/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.3397\n",
      "Epoch 8/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.7772\n",
      "Epoch 9/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.9327\n",
      "Epoch 10/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.2717\n",
      "Epoch 11/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.2392\n",
      "Epoch 12/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.9177\n",
      "Epoch 13/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.5240\n",
      "Epoch 14/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.4470\n",
      "Epoch 15/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.0350\n",
      "Epoch 16/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.9590\n",
      "Epoch 17/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6201\n",
      "Epoch 18/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7305\n",
      "Epoch 19/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.4157\n",
      "Epoch 20/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7208\n",
      "Epoch 21/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.8184\n",
      "Epoch 22/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6920\n",
      "Epoch 23/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5813\n",
      "Epoch 24/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6168\n",
      "Epoch 25/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5048\n",
      "Epoch 26/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.1541\n",
      "Epoch 27/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4338\n",
      "Epoch 28/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6408\n",
      "Epoch 29/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.4094\n",
      "Epoch 30/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3421\n",
      "Epoch 31/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5894\n",
      "Epoch 32/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3482\n",
      "Epoch 33/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.8668\n",
      "Epoch 34/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4872\n",
      "Epoch 35/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2865\n",
      "Epoch 36/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3705\n",
      "Epoch 37/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2813\n",
      "Epoch 38/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3217\n",
      "Epoch 39/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7066\n",
      "Epoch 40/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1107\n",
      "Epoch 41/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0905\n",
      "Epoch 42/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7101\n",
      "Epoch 43/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3248\n",
      "Epoch 44/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0571\n",
      "Epoch 45/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1900\n",
      "Epoch 46/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0291\n",
      "Epoch 47/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1349\n",
      "Epoch 48/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5464\n",
      "Epoch 49/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9337\n",
      "Epoch 50/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8174\n",
      "Epoch 51/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1287\n",
      "Epoch 52/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8663\n",
      "Epoch 53/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3327\n",
      "Epoch 54/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.1095\n",
      "Epoch 55/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0631\n",
      "Epoch 56/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1040\n",
      "Epoch 57/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8636\n",
      "Epoch 58/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8337\n",
      "Epoch 59/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9500\n",
      "Epoch 60/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1511\n",
      "Epoch 61/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2910\n",
      "Epoch 62/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2765\n",
      "Epoch 63/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7037\n",
      "Epoch 64/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8408\n",
      "Epoch 65/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9000\n",
      "Epoch 66/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7974\n",
      "Epoch 67/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9453\n",
      "Epoch 68/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7789\n",
      "Epoch 69/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7313\n",
      "Epoch 70/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6779\n",
      "Epoch 71/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8359\n",
      "Epoch 72/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9659\n",
      "Epoch 73/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8743\n",
      "Epoch 74/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3410\n",
      "Epoch 75/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9519\n",
      "Epoch 76/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6430\n",
      "Epoch 77/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6269\n",
      "Epoch 78/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5834\n",
      "Epoch 79/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4638\n",
      "Epoch 80/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3894\n",
      "Epoch 81/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6863\n",
      "Epoch 82/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7878\n",
      "Epoch 83/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1217\n",
      "Epoch 84/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7691\n",
      "Epoch 85/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4476\n",
      "Epoch 86/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6904\n",
      "Epoch 87/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4231\n",
      "Epoch 88/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4510\n",
      "Epoch 89/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8709\n",
      "Epoch 90/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0072\n",
      "Epoch 91/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5822\n",
      "Epoch 92/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7931\n",
      "Epoch 93/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9232\n",
      "Epoch 94/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7541\n",
      "Epoch 95/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5981\n",
      "Epoch 96/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4285\n",
      "Epoch 97/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6504\n",
      "Epoch 98/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5355\n",
      "Epoch 99/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7051\n",
      "Epoch 100/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5265\n",
      "Epoch 1/50\n",
      "952/952 [==============================] - 3s 3ms/step - loss: 2.3039\n",
      "Epoch 2/50\n",
      "952/952 [==============================] - 4s 4ms/step - loss: 2.4334\n",
      "Epoch 3/50\n",
      "952/952 [==============================] - 3s 3ms/step - loss: 2.9550\n",
      "Epoch 4/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4870\n",
      "Epoch 5/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5865\n",
      "Epoch 6/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4337\n",
      "Epoch 7/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2844\n",
      "Epoch 8/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6532\n",
      "Epoch 9/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5395\n",
      "Epoch 10/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3227\n",
      "Epoch 11/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5954\n",
      "Epoch 12/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5352\n",
      "Epoch 13/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4909\n",
      "Epoch 14/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6917\n",
      "Epoch 15/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3922\n",
      "Epoch 16/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4533\n",
      "Epoch 17/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3012\n",
      "Epoch 18/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5209\n",
      "Epoch 19/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7130\n",
      "Epoch 20/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6281\n",
      "Epoch 21/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3086\n",
      "Epoch 22/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3062\n",
      "Epoch 23/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4205\n",
      "Epoch 24/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3758\n",
      "Epoch 25/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2114\n",
      "Epoch 26/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2328\n",
      "Epoch 27/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2945\n",
      "Epoch 28/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4108\n",
      "Epoch 29/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1939\n",
      "Epoch 30/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2907\n",
      "Epoch 31/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4905\n",
      "Epoch 32/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2907\n",
      "Epoch 33/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1626\n",
      "Epoch 34/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3298\n",
      "Epoch 35/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5092\n",
      "Epoch 36/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2309\n",
      "Epoch 37/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3831\n",
      "Epoch 38/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6738\n",
      "Epoch 39/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4422\n",
      "Epoch 40/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4012\n",
      "Epoch 41/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4388\n",
      "Epoch 42/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2989\n",
      "Epoch 43/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0730\n",
      "Epoch 44/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0485\n",
      "Epoch 45/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1281\n",
      "Epoch 46/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1599\n",
      "Epoch 47/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3047\n",
      "Epoch 48/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4521\n",
      "Epoch 49/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0133\n",
      "Epoch 50/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2253\n",
      "Epoch 1/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1296\n",
      "Epoch 2/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2752\n",
      "Epoch 3/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1969\n",
      "Epoch 4/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2912\n",
      "Epoch 5/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8333\n",
      "Epoch 6/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2525\n",
      "Epoch 7/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0369\n",
      "Epoch 8/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1898\n",
      "Epoch 9/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0154\n",
      "Epoch 10/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1869\n",
      "Epoch 11/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5300\n",
      "Epoch 12/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1605\n",
      "Epoch 13/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1798\n",
      "Epoch 14/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1150\n",
      "Epoch 15/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1869\n",
      "Epoch 16/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3821\n",
      "Epoch 17/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2466\n",
      "Epoch 18/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1904\n",
      "Epoch 19/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1103\n",
      "Epoch 20/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1461\n",
      "Epoch 21/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9740\n",
      "Epoch 22/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1297\n",
      "Epoch 23/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9208\n",
      "Epoch 24/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4007\n",
      "Epoch 25/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1382\n",
      "Epoch 26/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1178\n",
      "Epoch 27/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9672\n",
      "Epoch 28/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2440\n",
      "Epoch 29/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9416\n",
      "Epoch 30/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1587\n",
      "Epoch 31/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1663\n",
      "Epoch 32/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0166\n",
      "Epoch 33/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0770\n",
      "Epoch 34/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9601\n",
      "Epoch 35/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0842\n",
      "Epoch 36/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2125\n",
      "Epoch 37/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1479\n",
      "Epoch 38/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0749\n",
      "Epoch 39/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9720\n",
      "Epoch 40/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0244\n",
      "Epoch 41/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0701\n",
      "Epoch 42/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0509\n",
      "Epoch 43/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0759\n",
      "Epoch 44/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8544\n",
      "Epoch 45/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8667\n",
      "Epoch 46/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9957\n",
      "Epoch 47/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9308\n",
      "Epoch 48/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8473\n",
      "Epoch 49/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9831\n",
      "Epoch 50/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9174\n",
      "Epoch 1/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 47.3192\n",
      "Epoch 2/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 10.1329\n",
      "Epoch 3/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 6.7438\n",
      "Epoch 4/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 7.4703\n",
      "Epoch 5/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.1349\n",
      "Epoch 6/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.3747\n",
      "Epoch 7/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.6849\n",
      "Epoch 8/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.5638\n",
      "Epoch 9/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.3515\n",
      "Epoch 10/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.5603\n",
      "Epoch 11/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.4324\n",
      "Epoch 12/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.0684\n",
      "Epoch 13/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.2766\n",
      "Epoch 14/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.8068\n",
      "Epoch 15/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.3619\n",
      "Epoch 16/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.5311\n",
      "Epoch 17/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6721\n",
      "Epoch 18/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6452\n",
      "Epoch 19/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6855\n",
      "Epoch 20/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.0903\n",
      "Epoch 21/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6710\n",
      "Epoch 22/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7825\n",
      "Epoch 23/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.2699\n",
      "Epoch 24/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.9257\n",
      "Epoch 25/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7219\n",
      "Epoch 26/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4579\n",
      "Epoch 27/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5146\n",
      "Epoch 28/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7397\n",
      "Epoch 29/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4255\n",
      "Epoch 30/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2635\n",
      "Epoch 31/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3715\n",
      "Epoch 32/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1783\n",
      "Epoch 33/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2834\n",
      "Epoch 34/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7691\n",
      "Epoch 35/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0657\n",
      "Epoch 36/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0809\n",
      "Epoch 37/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9843\n",
      "Epoch 38/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0990\n",
      "Epoch 39/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1139\n",
      "Epoch 40/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1116\n",
      "Epoch 41/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7464\n",
      "Epoch 42/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3298\n",
      "Epoch 43/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1489\n",
      "Epoch 44/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1722\n",
      "Epoch 45/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9884\n",
      "Epoch 46/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0592\n",
      "Epoch 47/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1311\n",
      "Epoch 48/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0118\n",
      "Epoch 49/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7684\n",
      "Epoch 50/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0402\n",
      "Epoch 51/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8486\n",
      "Epoch 52/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7513\n",
      "Epoch 53/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1027\n",
      "Epoch 54/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1383\n",
      "Epoch 55/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0997\n",
      "Epoch 56/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9396\n",
      "Epoch 57/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9230\n",
      "Epoch 58/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0378\n",
      "Epoch 59/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9093\n",
      "Epoch 60/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2023\n",
      "Epoch 61/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9380\n",
      "Epoch 62/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8678\n",
      "Epoch 63/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6689\n",
      "Epoch 64/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0156\n",
      "Epoch 65/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9619\n",
      "Epoch 66/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6215\n",
      "Epoch 67/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7285\n",
      "Epoch 68/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1752\n",
      "Epoch 69/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8524\n",
      "Epoch 70/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7525\n",
      "Epoch 71/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7508\n",
      "Epoch 72/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9765\n",
      "Epoch 73/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5056\n",
      "Epoch 74/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7339\n",
      "Epoch 75/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9680\n",
      "Epoch 76/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7049\n",
      "Epoch 77/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6134\n",
      "Epoch 78/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5747\n",
      "Epoch 79/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7847\n",
      "Epoch 80/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4677\n",
      "Epoch 81/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5484\n",
      "Epoch 82/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8103\n",
      "Epoch 83/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1660\n",
      "Epoch 84/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7900\n",
      "Epoch 85/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5690\n",
      "Epoch 86/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5149\n",
      "Epoch 87/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3128\n",
      "Epoch 88/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7285\n",
      "Epoch 89/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3967\n",
      "Epoch 90/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1778\n",
      "Epoch 91/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7521\n",
      "Epoch 92/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6924\n",
      "Epoch 93/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6367\n",
      "Epoch 94/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9252\n",
      "Epoch 95/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8235\n",
      "Epoch 96/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7243\n",
      "Epoch 97/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5539\n",
      "Epoch 98/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5844\n",
      "Epoch 99/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5453\n",
      "Epoch 100/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4936\n",
      "Epoch 1/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2195\n",
      "Epoch 2/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6291\n",
      "Epoch 3/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4154\n",
      "Epoch 4/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3586\n",
      "Epoch 5/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4334\n",
      "Epoch 6/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5700\n",
      "Epoch 7/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4831\n",
      "Epoch 8/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6434\n",
      "Epoch 9/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6328\n",
      "Epoch 10/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3054\n",
      "Epoch 11/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3636\n",
      "Epoch 12/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4555\n",
      "Epoch 13/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5682\n",
      "Epoch 14/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6225\n",
      "Epoch 15/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5897\n",
      "Epoch 16/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2016\n",
      "Epoch 17/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4490\n",
      "Epoch 18/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1910\n",
      "Epoch 19/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2696\n",
      "Epoch 20/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3933\n",
      "Epoch 21/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4923\n",
      "Epoch 22/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7887\n",
      "Epoch 23/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2880\n",
      "Epoch 24/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5531\n",
      "Epoch 25/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3174\n",
      "Epoch 26/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2058\n",
      "Epoch 27/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1683\n",
      "Epoch 28/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2389\n",
      "Epoch 29/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4649\n",
      "Epoch 30/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3793\n",
      "Epoch 31/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2390\n",
      "Epoch 32/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1970\n",
      "Epoch 33/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0815\n",
      "Epoch 34/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0880\n",
      "Epoch 35/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0791\n",
      "Epoch 36/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4198\n",
      "Epoch 37/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5201\n",
      "Epoch 38/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2952\n",
      "Epoch 39/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3266\n",
      "Epoch 40/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3882\n",
      "Epoch 41/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3471\n",
      "Epoch 42/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4317\n",
      "Epoch 43/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1834\n",
      "Epoch 44/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3379\n",
      "Epoch 45/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1142\n",
      "Epoch 46/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0341\n",
      "Epoch 47/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2333\n",
      "Epoch 48/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1789\n",
      "Epoch 49/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2918\n",
      "Epoch 50/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0442\n",
      "Epoch 1/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0540\n",
      "Epoch 2/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4679\n",
      "Epoch 3/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4304\n",
      "Epoch 4/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0433\n",
      "Epoch 5/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0396\n",
      "Epoch 6/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1870\n",
      "Epoch 7/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2656\n",
      "Epoch 8/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1836\n",
      "Epoch 9/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1483\n",
      "Epoch 10/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0063\n",
      "Epoch 11/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1836\n",
      "Epoch 12/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3766\n",
      "Epoch 13/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1792\n",
      "Epoch 14/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9832\n",
      "Epoch 15/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0982\n",
      "Epoch 16/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1820\n",
      "Epoch 17/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1414\n",
      "Epoch 18/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9357\n",
      "Epoch 19/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2487\n",
      "Epoch 20/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0967\n",
      "Epoch 21/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0125\n",
      "Epoch 22/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3040\n",
      "Epoch 23/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4041\n",
      "Epoch 24/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0077\n",
      "Epoch 25/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0547\n",
      "Epoch 26/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0837\n",
      "Epoch 27/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4586\n",
      "Epoch 28/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1760\n",
      "Epoch 29/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2943\n",
      "Epoch 30/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3036\n",
      "Epoch 31/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2344\n",
      "Epoch 32/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3464\n",
      "Epoch 33/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1098\n",
      "Epoch 34/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1220\n",
      "Epoch 35/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0614\n",
      "Epoch 36/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9675\n",
      "Epoch 37/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2539\n",
      "Epoch 38/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0458\n",
      "Epoch 39/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1353\n",
      "Epoch 40/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1027\n",
      "Epoch 41/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0841\n",
      "Epoch 42/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8248\n",
      "Epoch 43/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9273\n",
      "Epoch 44/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1661\n",
      "Epoch 45/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3738\n",
      "Epoch 46/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8617\n",
      "Epoch 47/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9318\n",
      "Epoch 48/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8985\n",
      "Epoch 49/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.7737\n",
      "Epoch 50/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8253\n",
      "Epoch 1/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 53.4400\n",
      "Epoch 2/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 10.0614\n",
      "Epoch 3/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 7.0038\n",
      "Epoch 4/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.5977\n",
      "Epoch 5/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.7870\n",
      "Epoch 6/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.5102\n",
      "Epoch 7/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.4990\n",
      "Epoch 8/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.4767\n",
      "Epoch 9/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.9463\n",
      "Epoch 10/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.4123\n",
      "Epoch 11/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.2482\n",
      "Epoch 12/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.3500\n",
      "Epoch 13/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.1575\n",
      "Epoch 14/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.7247\n",
      "Epoch 15/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.9081\n",
      "Epoch 16/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.9412\n",
      "Epoch 17/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.9907\n",
      "Epoch 18/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5671\n",
      "Epoch 19/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.5720\n",
      "Epoch 20/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7143\n",
      "Epoch 21/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5613\n",
      "Epoch 22/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6254\n",
      "Epoch 23/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3929\n",
      "Epoch 24/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.0924\n",
      "Epoch 25/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5558\n",
      "Epoch 26/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4796\n",
      "Epoch 27/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5835\n",
      "Epoch 28/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3206\n",
      "Epoch 29/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5873\n",
      "Epoch 30/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6097\n",
      "Epoch 31/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3684\n",
      "Epoch 32/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3649\n",
      "Epoch 33/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5956\n",
      "Epoch 34/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3401\n",
      "Epoch 35/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3148\n",
      "Epoch 36/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4193\n",
      "Epoch 37/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1415\n",
      "Epoch 38/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0850\n",
      "Epoch 39/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0666\n",
      "Epoch 40/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5805\n",
      "Epoch 41/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4368\n",
      "Epoch 42/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2100\n",
      "Epoch 43/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9595\n",
      "Epoch 44/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1846\n",
      "Epoch 45/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1372\n",
      "Epoch 46/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9022\n",
      "Epoch 47/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4221\n",
      "Epoch 48/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9419\n",
      "Epoch 49/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9192\n",
      "Epoch 50/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4135\n",
      "Epoch 51/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8422\n",
      "Epoch 52/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0359\n",
      "Epoch 53/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1033\n",
      "Epoch 54/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1414\n",
      "Epoch 55/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9739\n",
      "Epoch 56/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9874\n",
      "Epoch 57/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9608\n",
      "Epoch 58/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1160\n",
      "Epoch 59/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8158\n",
      "Epoch 60/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9880\n",
      "Epoch 61/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9710\n",
      "Epoch 62/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8600\n",
      "Epoch 63/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0686\n",
      "Epoch 64/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3883\n",
      "Epoch 65/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9363\n",
      "Epoch 66/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8556\n",
      "Epoch 67/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9866\n",
      "Epoch 68/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1102\n",
      "Epoch 69/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3059\n",
      "Epoch 70/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8227\n",
      "Epoch 71/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9580\n",
      "Epoch 72/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9849\n",
      "Epoch 73/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8720\n",
      "Epoch 74/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8454\n",
      "Epoch 75/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7280\n",
      "Epoch 76/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3149\n",
      "Epoch 77/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9691\n",
      "Epoch 78/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7460\n",
      "Epoch 79/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8440\n",
      "Epoch 80/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7945\n",
      "Epoch 81/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5311\n",
      "Epoch 82/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6025\n",
      "Epoch 83/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8048\n",
      "Epoch 84/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2181\n",
      "Epoch 85/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7837\n",
      "Epoch 86/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6486\n",
      "Epoch 87/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5844\n",
      "Epoch 88/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0256\n",
      "Epoch 89/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8929\n",
      "Epoch 90/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7623\n",
      "Epoch 91/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5971\n",
      "Epoch 92/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7728\n",
      "Epoch 93/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8414\n",
      "Epoch 94/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6327\n",
      "Epoch 95/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4600\n",
      "Epoch 96/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7496\n",
      "Epoch 97/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6794\n",
      "Epoch 98/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7289\n",
      "Epoch 99/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4847\n",
      "Epoch 100/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3927\n",
      "Epoch 1/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5144\n",
      "Epoch 2/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6750\n",
      "Epoch 3/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5368\n",
      "Epoch 4/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3269\n",
      "Epoch 5/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2493\n",
      "Epoch 6/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7546\n",
      "Epoch 7/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3424\n",
      "Epoch 8/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3091\n",
      "Epoch 9/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5372\n",
      "Epoch 10/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7013\n",
      "Epoch 11/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3380\n",
      "Epoch 12/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6020\n",
      "Epoch 13/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3334\n",
      "Epoch 14/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4308\n",
      "Epoch 15/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3155\n",
      "Epoch 16/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2999\n",
      "Epoch 17/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5847\n",
      "Epoch 18/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7777\n",
      "Epoch 19/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4002\n",
      "Epoch 20/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5270\n",
      "Epoch 21/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3589\n",
      "Epoch 22/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3154\n",
      "Epoch 23/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5218\n",
      "Epoch 24/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3314\n",
      "Epoch 25/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4291\n",
      "Epoch 26/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2205\n",
      "Epoch 27/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4458\n",
      "Epoch 28/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5414\n",
      "Epoch 29/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2160\n",
      "Epoch 30/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2313\n",
      "Epoch 31/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4451\n",
      "Epoch 32/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5450\n",
      "Epoch 33/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5569\n",
      "Epoch 34/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2406\n",
      "Epoch 35/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3027\n",
      "Epoch 36/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3442\n",
      "Epoch 37/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1628\n",
      "Epoch 38/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1376\n",
      "Epoch 39/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1934\n",
      "Epoch 40/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3773\n",
      "Epoch 41/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7249\n",
      "Epoch 42/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1492\n",
      "Epoch 43/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1805\n",
      "Epoch 44/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0014\n",
      "Epoch 45/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1740\n",
      "Epoch 46/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1691\n",
      "Epoch 47/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1581\n",
      "Epoch 48/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4476\n",
      "Epoch 49/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2231\n",
      "Epoch 50/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3679\n",
      "Epoch 1/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5076\n",
      "Epoch 2/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7827\n",
      "Epoch 3/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1731\n",
      "Epoch 4/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0252\n",
      "Epoch 5/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0640\n",
      "Epoch 6/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2676\n",
      "Epoch 7/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2007\n",
      "Epoch 8/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4144\n",
      "Epoch 9/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1621\n",
      "Epoch 10/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3353\n",
      "Epoch 11/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3755\n",
      "Epoch 12/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0825\n",
      "Epoch 13/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3062\n",
      "Epoch 14/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6066\n",
      "Epoch 15/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2556\n",
      "Epoch 16/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4921\n",
      "Epoch 17/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0760\n",
      "Epoch 18/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2258\n",
      "Epoch 19/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2295\n",
      "Epoch 20/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2635\n",
      "Epoch 21/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0112\n",
      "Epoch 22/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0158\n",
      "Epoch 23/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1788\n",
      "Epoch 24/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1792\n",
      "Epoch 25/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0508\n",
      "Epoch 26/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9588\n",
      "Epoch 27/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3628\n",
      "Epoch 28/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4913\n",
      "Epoch 29/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0152\n",
      "Epoch 30/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0533\n",
      "Epoch 31/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0214\n",
      "Epoch 32/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1788\n",
      "Epoch 33/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9030\n",
      "Epoch 34/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9381\n",
      "Epoch 35/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9891\n",
      "Epoch 36/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0182\n",
      "Epoch 37/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1416\n",
      "Epoch 38/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0645\n",
      "Epoch 39/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8360\n",
      "Epoch 40/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9804\n",
      "Epoch 41/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2023\n",
      "Epoch 42/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9736\n",
      "Epoch 43/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9504\n",
      "Epoch 44/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8569\n",
      "Epoch 45/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9553\n",
      "Epoch 46/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1723\n",
      "Epoch 47/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2608\n",
      "Epoch 48/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0878\n",
      "Epoch 49/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2150\n",
      "Epoch 50/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9963\n",
      "Epoch 1/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 40.3646\n",
      "Epoch 2/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 9.4326\n",
      "Epoch 3/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 8.8621\n",
      "Epoch 4/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 6.5718\n",
      "Epoch 5/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.8802\n",
      "Epoch 6/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.8962\n",
      "Epoch 7/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.2864\n",
      "Epoch 8/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.8229\n",
      "Epoch 9/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.8404\n",
      "Epoch 10/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.9741\n",
      "Epoch 11/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.3967\n",
      "Epoch 12/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.0872\n",
      "Epoch 13/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.8058\n",
      "Epoch 14/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.1365\n",
      "Epoch 15/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.9681\n",
      "Epoch 16/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7184\n",
      "Epoch 17/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7522\n",
      "Epoch 18/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5442\n",
      "Epoch 19/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4111\n",
      "Epoch 20/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7017\n",
      "Epoch 21/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7270\n",
      "Epoch 22/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7504\n",
      "Epoch 23/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.8821\n",
      "Epoch 24/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6056\n",
      "Epoch 25/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5595\n",
      "Epoch 26/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2051\n",
      "Epoch 27/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4806\n",
      "Epoch 28/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5502\n",
      "Epoch 29/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2569\n",
      "Epoch 30/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0728\n",
      "Epoch 31/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.8043\n",
      "Epoch 32/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1701\n",
      "Epoch 33/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2707\n",
      "Epoch 34/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4651\n",
      "Epoch 35/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4630\n",
      "Epoch 36/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2274\n",
      "Epoch 37/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6747\n",
      "Epoch 38/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1816\n",
      "Epoch 39/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1635\n",
      "Epoch 40/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0469\n",
      "Epoch 41/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0406\n",
      "Epoch 42/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0440\n",
      "Epoch 43/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8467\n",
      "Epoch 44/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8788\n",
      "Epoch 45/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0326\n",
      "Epoch 46/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0618\n",
      "Epoch 47/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1608\n",
      "Epoch 48/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0588\n",
      "Epoch 49/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9129\n",
      "Epoch 50/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0350\n",
      "Epoch 51/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0986\n",
      "Epoch 52/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1936\n",
      "Epoch 53/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9560\n",
      "Epoch 54/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8857\n",
      "Epoch 55/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9398\n",
      "Epoch 56/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8149\n",
      "Epoch 57/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0330\n",
      "Epoch 58/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2115\n",
      "Epoch 59/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9723\n",
      "Epoch 60/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8042\n",
      "Epoch 61/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7194\n",
      "Epoch 62/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8414\n",
      "Epoch 63/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7008\n",
      "Epoch 64/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9514\n",
      "Epoch 65/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7397\n",
      "Epoch 66/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8773\n",
      "Epoch 67/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9834\n",
      "Epoch 68/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8719\n",
      "Epoch 69/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1200\n",
      "Epoch 70/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8135\n",
      "Epoch 71/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8558\n",
      "Epoch 72/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9060\n",
      "Epoch 73/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7844\n",
      "Epoch 74/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7519\n",
      "Epoch 75/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6582\n",
      "Epoch 76/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6832\n",
      "Epoch 77/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8272\n",
      "Epoch 78/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6297\n",
      "Epoch 79/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6286\n",
      "Epoch 80/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4803\n",
      "Epoch 81/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6131\n",
      "Epoch 82/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7522\n",
      "Epoch 83/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8335\n",
      "Epoch 84/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7108\n",
      "Epoch 85/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0382\n",
      "Epoch 86/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7687\n",
      "Epoch 87/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7168\n",
      "Epoch 88/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6871\n",
      "Epoch 89/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4849\n",
      "Epoch 90/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4245\n",
      "Epoch 91/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4634\n",
      "Epoch 92/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6420\n",
      "Epoch 93/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5389\n",
      "Epoch 94/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6012\n",
      "Epoch 95/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6512\n",
      "Epoch 96/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5503\n",
      "Epoch 97/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4574\n",
      "Epoch 98/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2971\n",
      "Epoch 99/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5536\n",
      "Epoch 100/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5313\n",
      "Epoch 1/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6125\n",
      "Epoch 2/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5327\n",
      "Epoch 3/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5479\n",
      "Epoch 4/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2727\n",
      "Epoch 5/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5966\n",
      "Epoch 6/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1336\n",
      "Epoch 7/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6897\n",
      "Epoch 8/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2618\n",
      "Epoch 9/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1900\n",
      "Epoch 10/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3386\n",
      "Epoch 11/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4700\n",
      "Epoch 12/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2631\n",
      "Epoch 13/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4874\n",
      "Epoch 14/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3861\n",
      "Epoch 15/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2339\n",
      "Epoch 16/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2788\n",
      "Epoch 17/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3093\n",
      "Epoch 18/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4732\n",
      "Epoch 19/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7435\n",
      "Epoch 20/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3386\n",
      "Epoch 21/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2516\n",
      "Epoch 22/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2690\n",
      "Epoch 23/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3324\n",
      "Epoch 24/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1393\n",
      "Epoch 25/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0785\n",
      "Epoch 26/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2789\n",
      "Epoch 27/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2241\n",
      "Epoch 28/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3368\n",
      "Epoch 29/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2751\n",
      "Epoch 30/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2936\n",
      "Epoch 31/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3712\n",
      "Epoch 32/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3315\n",
      "Epoch 33/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2996\n",
      "Epoch 34/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3848\n",
      "Epoch 35/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1870\n",
      "Epoch 36/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1659\n",
      "Epoch 37/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8513\n",
      "Epoch 38/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4326\n",
      "Epoch 39/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3839\n",
      "Epoch 40/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3759\n",
      "Epoch 41/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6004\n",
      "Epoch 42/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4949\n",
      "Epoch 43/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4084\n",
      "Epoch 44/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3136\n",
      "Epoch 45/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3827\n",
      "Epoch 46/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3176\n",
      "Epoch 47/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1309\n",
      "Epoch 48/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0164\n",
      "Epoch 49/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0860\n",
      "Epoch 50/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2320\n",
      "Epoch 1/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1247\n",
      "Epoch 2/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0942\n",
      "Epoch 3/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2248\n",
      "Epoch 4/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1624\n",
      "Epoch 5/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3388\n",
      "Epoch 6/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0822\n",
      "Epoch 7/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1023\n",
      "Epoch 8/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1868\n",
      "Epoch 9/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9637\n",
      "Epoch 10/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1429\n",
      "Epoch 11/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9743\n",
      "Epoch 12/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0777\n",
      "Epoch 13/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5348\n",
      "Epoch 14/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3727\n",
      "Epoch 15/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2720\n",
      "Epoch 16/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0904\n",
      "Epoch 17/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0442\n",
      "Epoch 18/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8339\n",
      "Epoch 19/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1885\n",
      "Epoch 20/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0511\n",
      "Epoch 21/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0487\n",
      "Epoch 22/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0918\n",
      "Epoch 23/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0633\n",
      "Epoch 24/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9858\n",
      "Epoch 25/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3197\n",
      "Epoch 26/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0121\n",
      "Epoch 27/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0048\n",
      "Epoch 28/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0804\n",
      "Epoch 29/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2396\n",
      "Epoch 30/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3417\n",
      "Epoch 31/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3682\n",
      "Epoch 32/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1514\n",
      "Epoch 33/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1800\n",
      "Epoch 34/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1720\n",
      "Epoch 35/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1350\n",
      "Epoch 36/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0434\n",
      "Epoch 37/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1446\n",
      "Epoch 38/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1094\n",
      "Epoch 39/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0758\n",
      "Epoch 40/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8658\n",
      "Epoch 41/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9533\n",
      "Epoch 42/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0830\n",
      "Epoch 43/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1895\n",
      "Epoch 44/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0197\n",
      "Epoch 45/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8837\n",
      "Epoch 46/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9946\n",
      "Epoch 47/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0867\n",
      "Epoch 48/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0735\n",
      "Epoch 49/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1324\n",
      "Epoch 50/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9185\n",
      "Epoch 1/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 41.9342\n",
      "Epoch 2/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 9.9523\n",
      "Epoch 3/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 7.7043\n",
      "Epoch 4/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.5600\n",
      "Epoch 5/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 5.2072\n",
      "Epoch 6/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 6.6348\n",
      "Epoch 7/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.9510\n",
      "Epoch 8/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.4393\n",
      "Epoch 9/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.0982\n",
      "Epoch 10/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.6133\n",
      "Epoch 11/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.0261\n",
      "Epoch 12/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.9285\n",
      "Epoch 13/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7749\n",
      "Epoch 14/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.8589\n",
      "Epoch 15/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.2962\n",
      "Epoch 16/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6862\n",
      "Epoch 17/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 4.0245\n",
      "Epoch 18/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.8980\n",
      "Epoch 19/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7869\n",
      "Epoch 20/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4816\n",
      "Epoch 21/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5779\n",
      "Epoch 22/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.7148\n",
      "Epoch 23/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4669\n",
      "Epoch 24/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2853\n",
      "Epoch 25/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5230\n",
      "Epoch 26/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2509\n",
      "Epoch 27/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5053\n",
      "Epoch 28/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1820\n",
      "Epoch 29/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.8300\n",
      "Epoch 30/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5385\n",
      "Epoch 31/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.5755\n",
      "Epoch 32/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3037\n",
      "Epoch 33/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3979\n",
      "Epoch 34/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.6611\n",
      "Epoch 35/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3420\n",
      "Epoch 36/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1741\n",
      "Epoch 37/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0878\n",
      "Epoch 38/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.3219\n",
      "Epoch 39/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1294\n",
      "Epoch 40/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1271\n",
      "Epoch 41/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.4748\n",
      "Epoch 42/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9463\n",
      "Epoch 43/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1344\n",
      "Epoch 44/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1078\n",
      "Epoch 45/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0789\n",
      "Epoch 46/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0381\n",
      "Epoch 47/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1614\n",
      "Epoch 48/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1016\n",
      "Epoch 49/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.0595\n",
      "Epoch 50/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8673\n",
      "Epoch 51/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9425\n",
      "Epoch 52/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1622\n",
      "Epoch 53/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8754\n",
      "Epoch 54/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8937\n",
      "Epoch 55/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7848\n",
      "Epoch 56/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7898\n",
      "Epoch 57/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1725\n",
      "Epoch 58/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9996\n",
      "Epoch 59/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7253\n",
      "Epoch 60/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7327\n",
      "Epoch 61/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8108\n",
      "Epoch 62/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6094\n",
      "Epoch 63/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9532\n",
      "Epoch 64/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7117\n",
      "Epoch 65/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8680\n",
      "Epoch 66/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7613\n",
      "Epoch 67/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5997\n",
      "Epoch 68/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8231\n",
      "Epoch 69/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7313\n",
      "Epoch 70/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5199\n",
      "Epoch 71/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9181\n",
      "Epoch 72/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6272\n",
      "Epoch 73/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9553\n",
      "Epoch 74/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8900\n",
      "Epoch 75/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7447\n",
      "Epoch 76/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1466\n",
      "Epoch 77/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6243\n",
      "Epoch 78/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5272\n",
      "Epoch 79/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.2226\n",
      "Epoch 80/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4903\n",
      "Epoch 81/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6228\n",
      "Epoch 82/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 3.1523\n",
      "Epoch 83/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6107\n",
      "Epoch 84/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3742\n",
      "Epoch 85/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7280\n",
      "Epoch 86/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7179\n",
      "Epoch 87/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3864\n",
      "Epoch 88/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7645\n",
      "Epoch 89/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.9795\n",
      "Epoch 90/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6594\n",
      "Epoch 91/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5417\n",
      "Epoch 92/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3714\n",
      "Epoch 93/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2229\n",
      "Epoch 94/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4987\n",
      "Epoch 95/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6900\n",
      "Epoch 96/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4941\n",
      "Epoch 97/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5060\n",
      "Epoch 98/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3802\n",
      "Epoch 99/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3335\n",
      "Epoch 100/100\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3964\n",
      "Epoch 1/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3147\n",
      "Epoch 2/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3916\n",
      "Epoch 3/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3973\n",
      "Epoch 4/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.8287\n",
      "Epoch 5/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4082\n",
      "Epoch 6/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6239\n",
      "Epoch 7/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3695\n",
      "Epoch 8/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6002\n",
      "Epoch 9/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6350\n",
      "Epoch 10/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.7676\n",
      "Epoch 11/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4675\n",
      "Epoch 12/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3488\n",
      "Epoch 13/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2821\n",
      "Epoch 14/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2291\n",
      "Epoch 15/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3902\n",
      "Epoch 16/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3708\n",
      "Epoch 17/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1780\n",
      "Epoch 18/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.6403\n",
      "Epoch 19/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4147\n",
      "Epoch 20/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2359\n",
      "Epoch 21/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4485\n",
      "Epoch 22/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1982\n",
      "Epoch 23/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2564\n",
      "Epoch 24/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.5201\n",
      "Epoch 25/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3241\n",
      "Epoch 26/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1023\n",
      "Epoch 27/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2125\n",
      "Epoch 28/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2560\n",
      "Epoch 29/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1648\n",
      "Epoch 30/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1198\n",
      "Epoch 31/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2523\n",
      "Epoch 32/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2516\n",
      "Epoch 33/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1782\n",
      "Epoch 34/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9865\n",
      "Epoch 35/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1028\n",
      "Epoch 36/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1723\n",
      "Epoch 37/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2626\n",
      "Epoch 38/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0905\n",
      "Epoch 39/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2404\n",
      "Epoch 40/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2583\n",
      "Epoch 41/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3369\n",
      "Epoch 42/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1195\n",
      "Epoch 43/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3085\n",
      "Epoch 44/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3355\n",
      "Epoch 45/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9796\n",
      "Epoch 46/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0104\n",
      "Epoch 47/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1211\n",
      "Epoch 48/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2495\n",
      "Epoch 49/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3178\n",
      "Epoch 50/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3171\n",
      "Epoch 1/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1214\n",
      "Epoch 2/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2347\n",
      "Epoch 3/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3675\n",
      "Epoch 4/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0551\n",
      "Epoch 5/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8591\n",
      "Epoch 6/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2585\n",
      "Epoch 7/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4760\n",
      "Epoch 8/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0529\n",
      "Epoch 9/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2678\n",
      "Epoch 10/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3097\n",
      "Epoch 11/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2525\n",
      "Epoch 12/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4577\n",
      "Epoch 13/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.3589\n",
      "Epoch 14/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1292\n",
      "Epoch 15/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8981\n",
      "Epoch 16/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9829\n",
      "Epoch 17/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9307\n",
      "Epoch 18/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9259\n",
      "Epoch 19/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0974\n",
      "Epoch 20/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8703\n",
      "Epoch 21/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2661\n",
      "Epoch 22/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2007\n",
      "Epoch 23/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1966\n",
      "Epoch 24/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9477\n",
      "Epoch 25/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9619\n",
      "Epoch 26/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0325\n",
      "Epoch 27/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0212\n",
      "Epoch 28/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9609\n",
      "Epoch 29/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8898\n",
      "Epoch 30/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0879\n",
      "Epoch 31/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1708\n",
      "Epoch 32/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0451\n",
      "Epoch 33/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1322\n",
      "Epoch 34/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1333\n",
      "Epoch 35/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1049\n",
      "Epoch 36/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9401\n",
      "Epoch 37/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0097\n",
      "Epoch 38/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8250\n",
      "Epoch 39/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.2243\n",
      "Epoch 40/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.1996\n",
      "Epoch 41/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9895\n",
      "Epoch 42/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0328\n",
      "Epoch 43/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9294\n",
      "Epoch 44/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0425\n",
      "Epoch 45/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.4176\n",
      "Epoch 46/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8413\n",
      "Epoch 47/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.9693\n",
      "Epoch 48/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0451\n",
      "Epoch 49/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 1.8219\n",
      "Epoch 50/50\n",
      "952/952 [==============================] - 2s 2ms/step - loss: 2.0006\n"
     ]
    }
   ],
   "source": [
    "TRAIN = 1 # set TRAIN to 0 if you already have the weights in the directory.\n",
    "if TRAIN:\n",
    "    model.save_weights('model.h5')\n",
    "    \n",
    "    mape_list = []\n",
    "    history_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    for i in range(NUM_REPEAT):\n",
    "        model.load_weights('model.h5')\n",
    "        shuffle_weights(model)\n",
    "        \n",
    "        history_1 = model.fit(X_train_fit, Y_train_fit, \\\n",
    "                            epochs=100, batch_size=BATCH_SIZE, validation_data=None)\n",
    "        \n",
    "        model.save_weights('complete' + str(i+1) + '1_weights.h5')    \n",
    "        pred_1 = model.predict(X_test_pred)\n",
    "        pred_eval_1 = pred_1.reshape(24*NUM_TEST_DAYS) \n",
    "        \n",
    "        history_2 = model.fit(X_train_fit, Y_train_fit, \\\n",
    "                            epochs=50, batch_size=BATCH_SIZE, validation_data=None)\n",
    "        \n",
    "        model.save_weights('complete' + str(i+1) + '2_weights.h5') \n",
    "        pred_2 = model.predict(X_test_pred)\n",
    "        pred_eval_2 = pred_2.reshape(24*NUM_TEST_DAYS) \n",
    "        \n",
    "        history_3 = model.fit(X_train_fit, Y_train_fit, \\\n",
    "                            epochs=50, batch_size=BATCH_SIZE, validation_data=None)\n",
    "        \n",
    "        model.save_weights('complete' + str(i+1) +'3_weights.h5') \n",
    "        pred_3 = model.predict(X_test_pred)\n",
    "        pred_eval_3 = pred_3.reshape(24*NUM_TEST_DAYS) \n",
    "    \n",
    "        pred_list.append([pred_eval_1, pred_eval_2, pred_eval_3])\n",
    "        history_list.append([history_1, history_2, history_3])\n",
    "    \n",
    "    with h5py.File('results.h5', 'w') as h5f:\n",
    "        h5f.create_dataset('pred_list', data=pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WSn4GcYqVJPa"
   },
   "outputs": [],
   "source": [
    "p = np.zeros((NUM_REPEAT * NUM_SNAPSHOTS, 24 * NUM_TEST_DAYS))\n",
    "for i in range(NUM_REPEAT-1):\n",
    "    for j in range(NUM_SNAPSHOTS):\n",
    "        model.load_weights('/content/complete' + str(i+1) + str(j+1) + '_weights.h5')\n",
    "        pred = model.predict(X_test_pred)\n",
    "        p[i*NUM_SNAPSHOTS+j, :] = pred.reshape(24 * NUM_TEST_DAYS) \n",
    "pred_eval = np.mean(p, axis=0)\n",
    "Y_test_eval = np.array(Y_test).transpose().reshape(24 * NUM_TEST_DAYS)\n",
    "mape = np.mean(np.divide(np.abs(Y_test_eval - pred_eval), Y_test_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2303871,
     "status": "ok",
     "timestamp": 1593466874194,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "Fjo4vxtEBfw2",
    "outputId": "da8bfe70-0b96-4ead-f084-cfbf4f1ddcc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 8760)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fqswQ1fLT8Qk"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2303863,
     "status": "ok",
     "timestamp": 1593466874196,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "muRj-xMe_0j-",
    "outputId": "5755a842-dd85-4443-aa22-12b1a18136c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760,)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16G_Fo2UIPk4"
   },
   "outputs": [],
   "source": [
    "f = h5py.File('/content/drive/My Drive/exploproject/load-forecasting-resnet-master/ISO-NE/results.h5','r')\n",
    "ls = list(f.keys())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFDUzUVf-0OI"
   },
   "outputs": [],
   "source": [
    "with h5py.File('/content/drive/My Drive/exploproject/load-forecasting-resnet-master/ISO-NE/results.h5','r') as hdf:\n",
    "  ls = list(hdf.keys())\n",
    "  data = hdf.get('pred_list')\n",
    "  pred_list = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2304619,
     "status": "ok",
     "timestamp": 1593466875053,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "z4MHK98dNzco",
    "outputId": "3bbc5d6d-056b-46d3-88f5-bd6323c7aed5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.53815264, 0.51136184, 0.4996558 , ..., 0.66476613,\n",
       "         0.6132186 , 0.5565864 ],\n",
       "        [0.5355804 , 0.512257  , 0.5008241 , ..., 0.65187657,\n",
       "         0.6054705 , 0.5534431 ],\n",
       "        [0.54097426, 0.5135273 , 0.50430137, ..., 0.6489526 ,\n",
       "         0.6031457 , 0.5477999 ]],\n",
       "\n",
       "       [[0.5282886 , 0.5038254 , 0.49147764, ..., 0.65607935,\n",
       "         0.6013978 , 0.5450853 ],\n",
       "        [0.5306509 , 0.51083446, 0.4986627 , ..., 0.6520463 ,\n",
       "         0.5995697 , 0.5445029 ],\n",
       "        [0.53069574, 0.5127821 , 0.5025772 , ..., 0.6490294 ,\n",
       "         0.5998126 , 0.5462805 ]]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2304574,
     "status": "ok",
     "timestamp": 1593466875057,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "kqJCk9mEN2Pa",
    "outputId": "65651574-d002-480d-c793-823c3c03ab03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 8760)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2304535,
     "status": "ok",
     "timestamp": 1593466875059,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "bWET-Gc8OC7Q",
    "outputId": "f8c75fbd-cc1c-4140-f9f4-78b2914f223d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42308748, 0.40189285, 0.39344186, ..., 0.53123069, 0.48883812,\n",
       "       0.45189205])"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2304505,
     "status": "ok",
     "timestamp": 1593466875061,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "zIl5kQvxIY5c",
    "outputId": "abc22b2a-9227-41fa-96ec-2c7089ca91df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53004167, 0.50554167, 0.494875  , ..., 0.66004167, 0.61045833,\n",
       "       0.56216667])"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1607,
     "status": "ok",
     "timestamp": 1593468736908,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "pZK5d6pGHgnO",
    "outputId": "7ea34ed2-6aff-49d2-823c-89436a7e2d78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_test</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.530042</td>\n",
       "      <td>0.423087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.505542</td>\n",
       "      <td>0.401893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.494875</td>\n",
       "      <td>0.393442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490667</td>\n",
       "      <td>0.390273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.492875</td>\n",
       "      <td>0.392309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>0.710167</td>\n",
       "      <td>0.574036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>0.690750</td>\n",
       "      <td>0.556071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>0.660042</td>\n",
       "      <td>0.531231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>0.610458</td>\n",
       "      <td>0.488838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>0.562167</td>\n",
       "      <td>0.451892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Y_test  Predicted\n",
       "0     0.530042   0.423087\n",
       "1     0.505542   0.401893\n",
       "2     0.494875   0.393442\n",
       "3     0.490667   0.390273\n",
       "4     0.492875   0.392309\n",
       "...        ...        ...\n",
       "8755  0.710167   0.574036\n",
       "8756  0.690750   0.556071\n",
       "8757  0.660042   0.531231\n",
       "8758  0.610458   0.488838\n",
       "8759  0.562167   0.451892\n",
       "\n",
       "[8760 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"Y_test\":Y_test_eval , \"Predicted\": pred_eval})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2304492,
     "status": "ok",
     "timestamp": 1593466875064,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "km6DjzMuBDLU",
    "outputId": "667a9106-f45d-4b85-9b0c-eea38a6a917b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19802025091079378"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MEAN ABSOLUTE ERROR\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Eu8zhJLVJPd"
   },
   "outputs": [],
   "source": [
    "VAL = False # only used for the plotting section hereafter\n",
    "# You can set the proportion of validation data in the training phase\n",
    "# or split the data into training and validation sets in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1576,
     "status": "error",
     "timestamp": 1593468194419,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "hSFu_jg1VJPh",
    "outputId": "b8af70f5-3561-4049-fcf1-efdafc4a38f6"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-9407df929475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mval_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_once\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_curve_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_once\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mval_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_once\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-9407df929475>\u001b[0m in \u001b[0;36mget_curve_data\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhistory_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhistory_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhistory_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "\n",
    "if VAL:\n",
    "    def get_curve_data(history):\n",
    "        loss = []\n",
    "        val_loss = []\n",
    "        for history_item in history:\n",
    "            loss = loss + history_item.history['loss']\n",
    "            val_loss = val_loss + history_item.history['val_loss']\n",
    "        return (np.array(loss), np.array(val_loss))\n",
    "    \n",
    "    loss_list = []\n",
    "    val_loss_list = []\n",
    "    for history in history_list:\n",
    "        loss_once, val_loss_once = get_curve_data(history)\n",
    "        loss_list.append(loss_once)\n",
    "        val_loss_list.append(val_loss_once)\n",
    "        \n",
    "    loss = np.array(loss_list)\n",
    "    val_loss = np.array(val_loss_list)\n",
    "    \n",
    "    loss_mean = np.mean(loss, axis=0)\n",
    "    loss_std = np.std(loss, axis=0)\n",
    "    loss_up = loss_mean + loss_std\n",
    "    loss_down = loss_mean - loss_std\n",
    "    \n",
    "    val_loss_mean = np.mean(val_loss, axis=0)\n",
    "    val_loss_std = np.std(val_loss, axis=0)\n",
    "    val_loss_up = val_loss_mean + val_loss_std\n",
    "    val_loss_down = val_loss_mean - val_loss_std\n",
    "    \n",
    "    x = range(200)\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(x, loss_mean, color='Green')\n",
    "    plt.fill_between(x, loss_up, loss_down, color='LightGreen', alpha=0.7) \n",
    "    plt.plot(val_loss_mean, color='RoyalBlue')\n",
    "    plt.fill_between(x, val_loss_up, val_loss_down, color='LightSkyBlue', alpha=0.7) \n",
    "    plt.axis([200,700,1,2.5])\n",
    "else:\n",
    "    def get_curve_data(history):\n",
    "        loss = []\n",
    "        for history_item in history:\n",
    "            loss = loss + history_item.history['loss']\n",
    "        return (np.array(loss))\n",
    "    \n",
    "    loss_list = []\n",
    "    for history in history_list:\n",
    "        loss_once = get_curve_data(history)\n",
    "        loss_list.append(loss_once)\n",
    "        \n",
    "    loss = np.array(loss_list)\n",
    "    \n",
    "    loss_mean = np.mean(loss, axis=0)\n",
    "    loss_std = np.std(loss, axis=0)\n",
    "    loss_up = loss_mean + loss_std\n",
    "    loss_down = loss_mean - loss_std\n",
    "    \n",
    "    x = range(200)\n",
    "    \n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(x, loss_mean, color='Green')\n",
    "    plt.fill_between(x, loss_up, loss_down, color='LightGreen', alpha=0.7) \n",
    "    plt.axis([200,700,1,2.5])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2304421,
     "status": "ok",
     "timestamp": 1593466875071,
     "user": {
      "displayName": "Aayushi Kunwar 4-Yr B.Tech. Electrical Engg., IIT(BHU), Varanasi",
      "photoUrl": "",
      "userId": "05117017905900632217"
     },
     "user_tz": -330
    },
    "id": "jKcT355qVJPo",
    "outputId": "a5fa475b-f335-462a-df4d-017ea6909eb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45.24956262, 10.38287256,  7.70036383,  6.37445819,  5.54561453,\n",
       "        5.62131786,  4.95218103,  4.81597665,  4.83382054,  4.56633809,\n",
       "        4.46852557,  4.07036158,  4.3077589 ,  4.19478818,  4.11386683,\n",
       "        3.96714787,  3.81190184,  3.67698473,  3.9742418 ,  3.74174425,\n",
       "        3.67110818,  3.71302941,  3.71861777,  3.70516861,  3.57299525,\n",
       "        3.50954498,  3.50355986,  3.48668054,  3.70182929,  3.36531344,\n",
       "        3.54180333,  3.27305056,  3.48287078,  3.5445135 ,  3.29442125,\n",
       "        3.25445052,  3.23391918,  3.20184046,  3.23601071,  3.19533876,\n",
       "        3.35781266,  3.24805114,  3.08284071,  3.08009415,  3.08542593,\n",
       "        3.0180771 ,  3.20205749,  3.1320991 ,  2.91873716,  3.03467096,\n",
       "        2.97213309,  3.00188112,  3.07400827,  3.23371076,  2.97225001,\n",
       "        2.92714062,  2.99058133,  3.03975319,  2.87454302,  2.97564986,\n",
       "        2.94604857,  2.89099928,  2.81902302,  2.98156729,  2.88117972,\n",
       "        2.78261118,  2.84870341,  2.95185178,  2.94816167,  2.71730019,\n",
       "        2.86370434,  2.89207421,  2.79831296,  2.91244329,  2.8101675 ,\n",
       "        2.89851   ,  2.73217699,  2.61217577,  2.78872012,  2.5244392 ,\n",
       "        2.60034601,  2.82101743,  2.9073356 ,  2.77243472,  2.71328535,\n",
       "        2.6680978 ,  2.48470961,  2.73134657,  2.92500091,  2.80626193,\n",
       "        2.58729339,  2.65435755,  2.63260978,  2.68239161,  2.64455631,\n",
       "        2.58934796,  2.56943661,  2.50521907,  2.52446358,  2.46810327,\n",
       "        2.59298663,  2.53237143,  2.57047904,  2.45477403,  2.45480972,\n",
       "        2.70316979,  2.43383008,  2.49355962,  2.50690123,  2.48711883,\n",
       "        2.44689667,  2.44092086,  2.432385  ,  2.47202337,  2.38427811,\n",
       "        2.32086613,  2.36445847,  2.52061273,  2.50817915,  2.42457775,\n",
       "        2.3719777 ,  2.37549225,  2.36382974,  2.38393999,  2.27211448,\n",
       "        2.20806256,  2.26903205,  2.35678011,  2.26294405,  2.26292752,\n",
       "        2.35962554,  2.32317932,  2.25574996,  2.20592838,  2.2361522 ,\n",
       "        2.26660409,  2.43597625,  2.32593241,  2.31731488,  2.36016926,\n",
       "        2.48962287,  2.2988628 ,  2.23075579,  2.2073768 ,  2.15572016,\n",
       "        2.13824258,  2.18959358,  2.26891823,  2.18639457,  2.23730768,\n",
       "        2.18744716,  2.37094589,  2.27854088,  2.11544339,  2.22696173,\n",
       "        2.20956246,  2.21628487,  2.20552146,  2.11144527,  2.19620782,\n",
       "        2.26318379,  2.23100347,  2.31177872,  2.24133202,  2.14216443,\n",
       "        2.22590554,  2.08779235,  2.02234617,  2.1748681 ,  2.08555966,\n",
       "        2.06250005,  2.14838405,  2.15270128,  2.10420402,  2.10503996,\n",
       "        2.04099074,  2.16293386,  2.19052963,  2.07611892,  2.18903433,\n",
       "        2.19222488,  2.14765224,  2.08042906,  2.06510147,  2.07490864,\n",
       "        2.03634089,  2.13952894,  2.02392687,  2.04869306,  2.03459182,\n",
       "        2.05986905,  1.99301802,  2.01447175,  1.98792532,  2.09941531,\n",
       "        1.97313828,  2.03586224,  1.99041548,  1.98522712,  1.93162566])"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JgNbLgpVJPu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of code.ipynb",
   "provenance": [
    {
     "file_id": "1_5YvO49TDTf4FNiUPFRItJAUasFrZXNq",
     "timestamp": 1593504191425
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
